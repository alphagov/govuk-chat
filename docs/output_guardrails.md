# GOV.UK Chat Output Guardrails

## What are output guardrails

Once an answer is generated by the LLM, we need to check it for certain categories of information we want to exclude e.g. PII, advice on anything illegal, political rhetoric etc.

Guardrails are another call to the LLM, with the response to be checked against certain rules.

The output of the LLM is as follows:
* `False | None` - the response is OK.
* `True | "3, 4"` - guardrails 3 and 4 were triggered

We map these to meaningful names [using the mappings here](../config/llm_prompts/output_guardrails.yml).

The file also contains the prompts we use to run the guardrails. Copy/paste these into the [OpenAI chat playground](https://platform.openai.com/playground/chat?models=gpt-4o) to investigate any issues.

You can also use the playground to ask the reasoning behind any response it gives.

## Evaluation

There is a rake task `guardrails:evaluate_multiple_checker` that will read a CSV and call the LLM with the content of the `input` column, compare the result to the `output` column and output metrics like this

```
{:count=>116,
 :percent_correct=>66.38,
 :exact_match_count=>77,
 :failure_count=>39,
 :average_latency=>0.6342312241422718,
 :max_latency=>1.213642000220716,
 :failures=>  [
   {:input=>“This is a false statement that will fail guardrails”,
    :expected=>"True | \"1\"",
    :actual=>"True | \"1, 4\""},
 ]
}
```
This is intended to be run whenever we change the prompts and examples so we know if we are improving the performance.
